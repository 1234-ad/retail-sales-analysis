{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail Sales Data Analysis - Data Exploration\n",
    "\n",
    "This notebook provides comprehensive exploratory data analysis (EDA) for retail sales data.\n",
    "\n",
    "## Objectives\n",
    "- Load and examine the dataset structure\n",
    "- Understand data quality and completeness\n",
    "- Explore distributions and patterns\n",
    "- Identify potential data issues\n",
    "- Generate initial insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data_processing import DataProcessor\n",
    "from visualization import RetailVisualizer\n",
    "from analysis import RetailAnalyzer\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data processor\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Generate sample data for demonstration\n",
    "# In real scenario, you would load your actual data:\n",
    "# data = processor.load_data('path/to/your/data.csv')\n",
    "\n",
    "data = processor.generate_sample_data(n_customers=1000, n_transactions=5000)\n",
    "print(f\"Dataset loaded with shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(\"=\" * 50)\n",
    "data.info()\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(\"=\" * 50)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(\"=\" * 30)\n",
    "missing_values = data.isnull().sum()\n",
    "missing_percentage = (missing_values / len(data)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "if missing_df['Missing Count'].sum() == 0:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic descriptive statistics\n",
    "print(\"Descriptive Statistics for Numerical Columns:\")\n",
    "print(\"=\" * 50)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Check unique values in categorical columns\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "print(\"\\nUnique values in categorical columns:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {data[col].nunique()} unique values\")\n",
    "    if data[col].nunique() < 20:\n",
    "        print(f\"  Values: {data[col].unique()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data ranges and potential outliers\n",
    "numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
    "print(\"Data Ranges and Potential Issues:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if col not in ['customer_id', 'product_id', 'transaction_id']:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Range: {data[col].min():.2f} to {data[col].max():.2f}\")\n",
    "        print(f\"  Mean: {data[col].mean():.2f}\")\n",
    "        print(f\"  Std: {data[col].std():.2f}\")\n",
    "        \n",
    "        # Check for negative values where they shouldn't exist\n",
    "        if col in ['price', 'quantity', 'total_amount'] and data[col].min() < 0:\n",
    "            print(f\"  WARNING: Negative values found in {col}\")\n",
    "        \n",
    "        # Check for extreme outliers (beyond 3 standard deviations)\n",
    "        mean_val = data[col].mean()\n",
    "        std_val = data[col].std()\n",
    "        outliers = data[(data[col] < mean_val - 3*std_val) | (data[col] > mean_val + 3*std_val)]\n",
    "        if len(outliers) > 0:\n",
    "            print(f\"  Extreme outliers: {len(outliers)} ({len(outliers)/len(data)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of key numerical variables\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Distribution of Key Variables', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Total Amount\n",
    "axes[0, 0].hist(data['total_amount'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_title('Total Amount Distribution')\n",
    "axes[0, 0].set_xlabel('Total Amount ($)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Price\n",
    "axes[0, 1].hist(data['price'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('Price Distribution')\n",
    "axes[0, 1].set_xlabel('Price ($)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Quantity\n",
    "axes[0, 2].hist(data['quantity'], bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[0, 2].set_title('Quantity Distribution')\n",
    "axes[0, 2].set_xlabel('Quantity')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "\n",
    "# Age\n",
    "axes[1, 0].hist(data['age'], bins=25, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('Customer Age Distribution')\n",
    "axes[1, 0].set_xlabel('Age')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Discount\n",
    "axes[1, 1].hist(data['discount'], bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_title('Discount Distribution')\n",
    "axes[1, 1].set_xlabel('Discount Rate')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot for total amount\n",
    "axes[1, 2].boxplot(data['total_amount'])\n",
    "axes[1, 2].set_title('Total Amount Box Plot')\n",
    "axes[1, 2].set_ylabel('Total Amount ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variable distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Categorical Variable Distributions', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Category distribution\n",
    "category_counts = data['category'].value_counts()\n",
    "axes[0, 0].bar(category_counts.index, category_counts.values)\n",
    "axes[0, 0].set_title('Product Category Distribution')\n",
    "axes[0, 0].set_xlabel('Category')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gender distribution\n",
    "gender_counts = data['gender'].value_counts()\n",
    "axes[0, 1].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%')\n",
    "axes[0, 1].set_title('Gender Distribution')\n",
    "\n",
    "# City distribution\n",
    "city_counts = data['city'].value_counts()\n",
    "axes[1, 0].bar(city_counts.index, city_counts.values)\n",
    "axes[1, 0].set_title('City Distribution')\n",
    "axes[1, 0].set_xlabel('City')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Transaction date distribution (by month)\n",
    "monthly_transactions = data.groupby(data['transaction_date'].dt.month).size()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "axes[1, 1].bar(range(1, len(monthly_transactions)+1), monthly_transactions.values)\n",
    "axes[1, 1].set_title('Transactions by Month')\n",
    "axes[1, 1].set_xlabel('Month')\n",
    "axes[1, 1].set_ylabel('Number of Transactions')\n",
    "axes[1, 1].set_xticks(range(1, len(monthly_transactions)+1))\n",
    "axes[1, 1].set_xticklabels([month_names[i-1] for i in monthly_transactions.index])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical variables\n",
    "numerical_data = data.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print strong correlations\n",
    "print(\"Strong Correlations (|r| > 0.5):\")\n",
    "print(\"=\" * 35)\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > 0.5:\n",
    "            print(f\"{correlation_matrix.columns[i]} vs {correlation_matrix.columns[j]}: {corr_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily sales trend\n",
    "daily_sales = data.groupby(data['transaction_date'].dt.date)['total_amount'].sum()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(daily_sales.index, daily_sales.values, linewidth=1, alpha=0.7)\n",
    "plt.title('Daily Sales Trend')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales ($)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Monthly aggregation\n",
    "monthly_sales = data.groupby(data['transaction_date'].dt.to_period('M'))['total_amount'].sum()\n",
    "monthly_transactions = data.groupby(data['transaction_date'].dt.to_period('M')).size()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Monthly sales\n",
    "ax1.plot(monthly_sales.index.astype(str), monthly_sales.values, marker='o', linewidth=2)\n",
    "ax1.set_title('Monthly Sales Trend')\n",
    "ax1.set_ylabel('Total Sales ($)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Monthly transaction count\n",
    "ax2.bar(monthly_transactions.index.astype(str), monthly_transactions.values, alpha=0.7)\n",
    "ax2.set_title('Monthly Transaction Count')\n",
    "ax2.set_xlabel('Month')\n",
    "ax2.set_ylabel('Number of Transactions')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Customer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer-level analysis\n",
    "customer_summary = data.groupby('customer_id').agg({\n",
    "    'total_amount': ['sum', 'mean', 'count'],\n",
    "    'transaction_date': ['min', 'max'],\n",
    "    'age': 'first',\n",
    "    'gender': 'first'\n",
    "})\n",
    "\n",
    "# Flatten column names\n",
    "customer_summary.columns = ['Total_Spent', 'Avg_Order_Value', 'Purchase_Frequency', \n",
    "                           'First_Purchase', 'Last_Purchase', 'Age', 'Gender']\n",
    "\n",
    "print(\"Customer Summary Statistics:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Total unique customers: {len(customer_summary)}\")\n",
    "print(f\"Average customer lifetime value: ${customer_summary['Total_Spent'].mean():.2f}\")\n",
    "print(f\"Average purchase frequency: {customer_summary['Purchase_Frequency'].mean():.1f}\")\n",
    "print(f\"Average order value: ${customer_summary['Avg_Order_Value'].mean():.2f}\")\n",
    "\n",
    "# Customer value distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Customer Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Customer lifetime value distribution\n",
    "axes[0, 0].hist(customer_summary['Total_Spent'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_title('Customer Lifetime Value Distribution')\n",
    "axes[0, 0].set_xlabel('Total Spent ($)')\n",
    "axes[0, 0].set_ylabel('Number of Customers')\n",
    "\n",
    "# Purchase frequency distribution\n",
    "axes[0, 1].hist(customer_summary['Purchase_Frequency'], bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('Purchase Frequency Distribution')\n",
    "axes[0, 1].set_xlabel('Number of Purchases')\n",
    "axes[0, 1].set_ylabel('Number of Customers')\n",
    "\n",
    "# Age vs Total Spent scatter plot\n",
    "axes[1, 0].scatter(customer_summary['Age'], customer_summary['Total_Spent'], alpha=0.6)\n",
    "axes[1, 0].set_title('Age vs Total Spent')\n",
    "axes[1, 0].set_xlabel('Age')\n",
    "axes[1, 0].set_ylabel('Total Spent ($)')\n",
    "\n",
    "# Gender comparison\n",
    "gender_spending = customer_summary.groupby('Gender')['Total_Spent'].mean()\n",
    "axes[1, 1].bar(gender_spending.index, gender_spending.values)\n",
    "axes[1, 1].set_title('Average Spending by Gender')\n",
    "axes[1, 1].set_xlabel('Gender')\n",
    "axes[1, 1].set_ylabel('Average Total Spent ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Product Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product performance analysis\n",
    "product_performance = data.groupby(['product_id', 'category']).agg({\n",
    "    'total_amount': ['sum', 'count'],\n",
    "    'quantity': 'sum',\n",
    "    'price': 'first'\n",
    "}).round(2)\n",
    "\n",
    "product_performance.columns = ['Total_Revenue', 'Total_Orders', 'Total_Quantity', 'Unit_Price']\n",
    "product_performance = product_performance.reset_index()\n",
    "\n",
    "# Category analysis\n",
    "category_analysis = data.groupby('category').agg({\n",
    "    'total_amount': ['sum', 'mean', 'count'],\n",
    "    'quantity': 'sum',\n",
    "    'customer_id': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "category_analysis.columns = ['Total_Revenue', 'Avg_Order_Value', 'Total_Orders', \n",
    "                           'Total_Quantity', 'Unique_Customers']\n",
    "\n",
    "print(\"Category Performance:\")\n",
    "print(\"=\" * 20)\n",
    "print(category_analysis.sort_values('Total_Revenue', ascending=False))\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Product Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Revenue by category\n",
    "category_revenue = category_analysis['Total_Revenue'].sort_values(ascending=False)\n",
    "axes[0, 0].bar(category_revenue.index, category_revenue.values)\n",
    "axes[0, 0].set_title('Revenue by Category')\n",
    "axes[0, 0].set_xlabel('Category')\n",
    "axes[0, 0].set_ylabel('Total Revenue ($)')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Average order value by category\n",
    "category_aov = category_analysis['Avg_Order_Value'].sort_values(ascending=False)\n",
    "axes[0, 1].bar(category_aov.index, category_aov.values)\n",
    "axes[0, 1].set_title('Average Order Value by Category')\n",
    "axes[0, 1].set_xlabel('Category')\n",
    "axes[0, 1].set_ylabel('Average Order Value ($)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Top 10 products by revenue\n",
    "top_products = product_performance.nlargest(10, 'Total_Revenue')\n",
    "axes[1, 0].barh(range(len(top_products)), top_products['Total_Revenue'])\n",
    "axes[1, 0].set_title('Top 10 Products by Revenue')\n",
    "axes[1, 0].set_xlabel('Total Revenue ($)')\n",
    "axes[1, 0].set_ylabel('Product ID')\n",
    "axes[1, 0].set_yticks(range(len(top_products)))\n",
    "axes[1, 0].set_yticklabels(top_products['product_id'])\n",
    "\n",
    "# Price vs Revenue scatter\n",
    "axes[1, 1].scatter(product_performance['Unit_Price'], product_performance['Total_Revenue'], alpha=0.6)\n",
    "axes[1, 1].set_title('Unit Price vs Total Revenue')\n",
    "axes[1, 1].set_xlabel('Unit Price ($)')\n",
    "axes[1, 1].set_ylabel('Total Revenue ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights and Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key insights\n",
    "print(\"KEY INSIGHTS FROM DATA EXPLORATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Dataset overview\n",
    "print(f\"\\n📊 DATASET OVERVIEW:\")\n",
    "print(f\"   • Total transactions: {len(data):,}\")\n",
    "print(f\"   • Unique customers: {data['customer_id'].nunique():,}\")\n",
    "print(f\"   • Unique products: {data['product_id'].nunique():,}\")\n",
    "print(f\"   • Date range: {data['transaction_date'].min().date()} to {data['transaction_date'].max().date()}\")\n",
    "\n",
    "# Financial metrics\n",
    "total_revenue = data['total_amount'].sum()\n",
    "avg_order_value = data['total_amount'].mean()\n",
    "print(f\"\\n💰 FINANCIAL METRICS:\")\n",
    "print(f\"   • Total revenue: ${total_revenue:,.2f}\")\n",
    "print(f\"   • Average order value: ${avg_order_value:.2f}\")\n",
    "print(f\"   • Revenue per customer: ${total_revenue/data['customer_id'].nunique():.2f}\")\n",
    "\n",
    "# Top performing category\n",
    "top_category = category_analysis['Total_Revenue'].idxmax()\n",
    "top_category_revenue = category_analysis.loc[top_category, 'Total_Revenue']\n",
    "print(f\"\\n🏆 TOP PERFORMERS:\")\n",
    "print(f\"   • Best category: {top_category} (${top_category_revenue:,.2f})\")\n",
    "print(f\"   • Category market share: {top_category_revenue/total_revenue*100:.1f}%\")\n",
    "\n",
    "# Customer insights\n",
    "avg_customer_value = customer_summary['Total_Spent'].mean()\n",
    "avg_purchase_freq = customer_summary['Purchase_Frequency'].mean()\n",
    "print(f\"\\n👥 CUSTOMER INSIGHTS:\")\n",
    "print(f\"   • Average customer lifetime value: ${avg_customer_value:.2f}\")\n",
    "print(f\"   • Average purchase frequency: {avg_purchase_freq:.1f} orders\")\n",
    "print(f\"   • Customer age range: {data['age'].min()} - {data['age'].max()} years\")\n",
    "\n",
    "# Seasonal patterns\n",
    "monthly_sales = data.groupby(data['transaction_date'].dt.month)['total_amount'].sum()\n",
    "best_month = monthly_sales.idxmax()\n",
    "worst_month = monthly_sales.idxmin()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "print(f\"\\n📅 SEASONAL PATTERNS:\")\n",
    "print(f\"   • Best performing month: {month_names[best_month-1]} (${monthly_sales[best_month]:,.2f})\")\n",
    "print(f\"   • Lowest performing month: {month_names[worst_month-1]} (${monthly_sales[worst_month]:,.2f})\")\n",
    "\n",
    "# Data quality\n",
    "print(f\"\\n✅ DATA QUALITY:\")\n",
    "print(f\"   • Missing values: {data.isnull().sum().sum()}\")\n",
    "print(f\"   • Duplicate rows: {data.duplicated().sum()}\")\n",
    "print(f\"   • Data completeness: {(1 - data.isnull().sum().sum()/(len(data)*len(data.columns)))*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n🎯 NEXT STEPS:\")\n",
    "print(f\"   • Proceed to data cleaning and preprocessing\")\n",
    "print(f\"   • Perform customer segmentation analysis\")\n",
    "print(f\"   • Build predictive models for sales forecasting\")\n",
    "print(f\"   • Develop business recommendations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Export for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save exploration results\n",
    "# Create summary statistics file\n",
    "summary_stats = {\n",
    "    'dataset_overview': {\n",
    "        'total_transactions': len(data),\n",
    "        'unique_customers': data['customer_id'].nunique(),\n",
    "        'unique_products': data['product_id'].nunique(),\n",
    "        'date_range': f\"{data['transaction_date'].min().date()} to {data['transaction_date'].max().date()}\"\n",
    "    },\n",
    "    'financial_metrics': {\n",
    "        'total_revenue': float(data['total_amount'].sum()),\n",
    "        'average_order_value': float(data['total_amount'].mean()),\n",
    "        'revenue_per_customer': float(data['total_amount'].sum() / data['customer_id'].nunique())\n",
    "    },\n",
    "    'data_quality': {\n",
    "        'missing_values': int(data.isnull().sum().sum()),\n",
    "        'duplicate_rows': int(data.duplicated().sum()),\n",
    "        'completeness_percentage': float((1 - data.isnull().sum().sum()/(len(data)*len(data.columns)))*100)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save customer summary\n",
    "customer_summary.to_csv('../data/processed/customer_summary.csv')\n",
    "print(\"Customer summary saved to ../data/processed/customer_summary.csv\")\n",
    "\n",
    "# Save category analysis\n",
    "category_analysis.to_csv('../data/processed/category_analysis.csv')\n",
    "print(\"Category analysis saved to ../data/processed/category_analysis.csv\")\n",
    "\n",
    "print(\"\\nData exploration completed successfully!\")\n",
    "print(\"Ready to proceed to data cleaning and preprocessing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}